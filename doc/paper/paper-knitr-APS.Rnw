\documentclass{article}
\usepackage{fancyhdr}
\usepackage{time}
\usepackage{authblk}
\usepackage{amsmath, amssymb}
\usepackage{caption}
\captionsetup[table]{textfont={large},labelfont={normalsize},labelsep=newline,justification=justified,singlelinecheck=true, skip=0pt}
\captionsetup[figure]{textfont={large},labelfont={normalsize},labelsep=newline,justification=justified,singlelinecheck=true, skip=0pt}
%\usepackage{fullpage}
%\usepackage{rotating}
%\usepackage{xcolor}
\usepackage[hyphens]{url}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=black]{hyperref}
%\usepackage{breakurl}
\usepackage{times}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{array}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{adjustbox}
%\usepackage{floatpag}
%\onehalfspacing
\doublespace
\usepackage[longnamesfirst]{natbib}
%\usepackage[natbibapa,longnamesfist]{apacite}

\DeclareMathOperator*{\argmax}{arg\,max}
%\newcommand{\r}{\Sexpr{}}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator*{\median}{median}
%\newcommand{\theHalgorithm}{\arabic{algorithm}}
\newcommand{\tr}{\textit{true}}
\newcommand{\naive}{\textit{recent}}
\newcommand{\default}{\textit{all-time}}
\newcommand{\market}{\textit{market}}
\newcolumntype{Y}{>{\raggedleft\arraybackslash}X}% raggedleft column X
%\newcommand{\raw}{\textit{raw}}
%\newcommand{\diff}{\textit{diff}}
%\newcommand{\random}{\textit{random}}
%\newcommand{\rollsd}{\textit{roll.sd}}


\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}

%-------------------------------------------------------------------------
% take the % away on next line to produce the final camera-ready version
% Be sure to remove \thispagestyle{fancy} as well after the \maketitle.
%\pagestyle{empty}
\pagestyle{fancy}
 
\newcommand\myTime{\now}
\fancyhead{}
\fancyhead[CO, CE]{\texttt{-Draft-}}
\fancyhead[RO, RE]{\texttt{\today, \myTime}}
\setlength{\headheight}{2\baselineskip}
\renewcommand{\headrulewidth}{0pt}
%-------------------------------------------------------------------------


\begin{document}

<<include=FALSE>>=
library(knitr)
opts_chunk$set(concordance=TRUE)
options(digits = 3)
@


<<load.data,echo=F,warning=FALSE,message=FALSE>>=
strategies <- c('true','recent','all-time')
setwd('~/Dropbox/workspace/Projects/BL-strategies')
library(reshape2)
library(descr)
library(data.table)
library(ggplot2)
library(stringr)
library(zoo)
library(xtable)
library(abind)
library(PerformanceAnalytics)
load('cache/q.data.RData')
load('cache/final.bl.RData')
load('cache/market.set.RData')
load('cache/example.dt.RData')
source('lib/aux.functions.R')
#library(ProjectTemplate)
#load.project()
###ADD NAs for the case of no ranking ( if NA, no raking)
trunk.percent <- 0.05
stocks <- unique(market.set[,Stock])
#q.data[,quantile(b.view,c(trunk.percent,1-trunk.percent),na.rm=T)]
q.data.full <- setkey(q.data[,':='(year=format(s.Date,'%Y'))],Stock)

q.data <- na.omit(q.data.full[stocks])
q.data <- q.data[,trunk.view:=truncate.f(b.view,trunk.percent)]
#stats.q.data <- summary.stat(q.data[!is.na(trunk.view),])

### General stat of TP/P-1
#stats.tper <- setnames(rbind(q.data[!is.na(trunk.view),mean(trunk.view,na.rm=T),by=list(year)],data.table(cbind(year='All',V1=q.data[!is.na(trunk.view),mean(trunk.view,na.rm=T)])))[,V1:=as.numeric(as.character(V1))],'V1','TP/P-1')

core.dt <- na.omit(q.data)[,core.b:=.N>=12,by=list(Stock,Broker)][(core.b)][,rank:=rank(score),by=list(q.id,Stock)][,core.s:=.N>=3,by=list(q.id,Stock)][(core.s)]

#pt.contin.dt <- unique(core.dt[,cont.rank:=.N>8,by=.(q.id,Stock)][(cont.rank)],by=c('q.id','Broker','Stock'))
quarters <- data.table(q.id=core.dt[order(q.id)][,unique(q.id)])

load('cache/ranked.pt.dt.RData')
n <- 3
n.b <- 3

#options(descr.na.replacement = "noRank")
pt.cont.tab <- abind(lapply(c(1,4),function(i) {cont.tab.f(ranked.pt.dt,i,n.b)}),along=4,new.names=list(NULL,NULL,NULL,c('t','t+4')))

###Statistics for views:
###non rank base data
load('cache/nr.views.RData')
load('cache/pt.rank.views.RData')
load('cache/eps.rank.views.RData')
load('cache/ranked.eps.dt.RData')
load('~/Dropbox/workspace/Projects/EPS/cache/complete.dt.RData')

complete.dt <- setkey(complete.dt,fis.q)[quarters]
eps.stocks <- intersect(complete.dt$Stock,unique(market.set[,Stock]))
complete.dt <- setnames(na.omit(setkey(complete.dt,Stock)[eps.stocks][,eps.pmafe:=abs(Est-act.eps)/mean(abs(Est-act.eps))])[,q.id:=NULL],'fis.q','q.id')

eps.cont.tab <- abind(lapply(c(1,4),function(i) {cont.tab.f(ranked.eps.dt,i,n.b)}),along=4,new.names=list(NULL,NULL,NULL,c('t','t+4')))

brok.full.stat.pt <- rbind(setkey(na.omit(core.dt)[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.character(median(N)),max=max(N),st.dev=sd(N)),by=year],year),setnames(cbind('Total',na.omit(core.dt)[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.character(median(N)),max=max(N),st.dev=sd(N))]),1,'year'))

#Views stat

stat.nr <- rbind(na.omit(nr.views)[,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method,type)],setnames(cbind('Total',na.omit(nr.views)[,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method,type)]),1,'year'))[,Strategy:='CONS']

stat.pt.view <- rbind(pt.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method,type)],setnames(cbind('Total',pt.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method,type)]),1,'year'))[,Strategy:='PT']

stat.eps.view <- rbind(eps.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(year,Method,type)],setnames(cbind('Total',eps.rank.views[View!=0,list(mean=mean(View),median=median(View),st.dev=sd(View),Stocks=length(unique(Stock))),by=.(Method,type)]),1,'year'))[,Strategy:='EPS']

stat.full <- rbind(stat.nr,stat.pt.view,stat.eps.view)

test <- melt(stat.full,id.vars = c('year','Method','Strategy','type'))
test.a <- acast(test,year~Method~Strategy~variable~type,value.var = 'value')


brok.full.stat.eps <- rbind(setkey(na.omit(complete.dt)[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.character(median(N)),max=max(N),st.dev=sd(N)),by=year],year),setnames(cbind('Total',na.omit(complete.dt)[,.N,by=.(Stock,q.id,year)][,list(min=min(N),mean=mean(N),median=as.character(median(N)),max=max(N),st.dev=sd(N))]),1,'year'))

load('~/Dropbox/workspace/Projects/EPS/cache/eps.dt.RData')

final.bl <- final.bl[,Method:=ifelse(Method=='true',strategies[1],ifelse(Method=='naive',strategies[2],strategies[3]))]

final.bl$Method <- factor(final.bl$Method,levels=strategies)
final.bl$Views <- factor(final.bl$Views,levels=c('CONS','TP','EPS','Market'))
final.bl <- final.bl[,ann.ret:=ann.ret*100][,ann.st:=ann.sd*100]
bl.results <- acast(unique(melt(data = final.bl,id.vars = c('Method','Views','type'),measure.vars  = c('ann.ret','ann.st','ann.sr','meanViews','Ave.TO')),by=c('Method','variable','Views','type')),Views~Method~variable~type,value.var = 'value')



quarters <- unique(final.bl[,Quarters])
periods.id <- c(paste(gsub('[[:space:]]','',rollapplyr(as.character(quarters),20,first,by=4)),gsub('[[:space:]]','',rollapplyr(as.character(quarters),20,last,by=4)),sep='/'),'All period')

periods <- rbind(final.bl[,data.table(rollapplyr(port.ret,20,roll.ret.f,by=4,partial=F)),by=.(Views,Method,type)][,strat:='yes'],final.bl[,data.table(rollapplyr(ns.port.ret,20,roll.ret.f,by=4,partial=F)),by=.(Views,Method,type)][,strat:='no'],final.bl[,data.table(roll.ret.f(port.ret)),by=.(Views,Method,type)][,strat:='yes'],final.bl[,data.table(roll.ret.f(ns.port.ret)),by=.(Views,Method,type)][,strat:='no'])[,period:=periods.id,by=.(Views,Method,strat,type)][,sr:=ann.ret/ann.sd]


periods.array <- acast(melt(periods,id.vars = c('Views','Method','period','strat','type')),period~Views~Method~strat~variable~type,value.var = 'value')

sel.s <- 'same'

test.a[,'true','CONS',,] <- NA
bl.results['CONS','true',,] <- NA
periods.array[,'CONS','true',,,] <- NA

start.year <- format(as.Date(final.bl[,head(Quarters,1)]),'%Y')
end.year <- format(as.Date(final.bl[,tail(Quarters,1)]),'%Y')
@

\title{Are rankings of financial analysts useful to investors?}
 \author[1,2]{ Artur Aiguzhinov (\href{mailto:artur.aiguzhinov@inescporto.pt}{artur.aiguzhinov@inescporto.pt})}
 \author[1]{ Ana Paula Serra (\href{mailto:aserra@fep.up.pt}{aserra@fep.up.pt})}
 \author[2,4]{Carlos Soares (\href{mailto:csoares@fe.up.pt}{csoares@fe.up.pt})}

\affil[1]{FEP \& CEF.UP, University of Porto}
\affil[2]{INESC TEC}
\affil[4]{FEUP, University of Porto}


\maketitle
% You need this here, or else the first page won't have a header.
\thispagestyle{fancy}

\begin{abstract}
Several institutions issue rankings based on the accuracy of price and EPS forecasts. Given that these rankings are \textit{ex-post} they may not be able useful to investors. In this paper  we show that trading strategies based on perfect foresight and past rankings outperform a passive strategy.  In addition, we report that investors are better off following analysts that issue  accurate price targets rather that those with accurate EPS forecasts. 
%Finally, we show that a strategy based on the perfect foresight of analysts' performance gains the highest cumulative return.
\end{abstract}

\section{Introduction}
\label{sec:intro}

% citations  full for aurtors
The idea that financial analysts play an important role in financial markets is rather consensual \citep{cowles1933csm,obrien1990}. Yet there is some debate on whether following the advice of analysts brings value to investors after transaction costs \citep{womack1996,mikhail2004sae,li2005persistence}. Related to this is the difficulty in identifying the analysts with superior stock picking skills. In this paper, we show that the rankings of financial analysts are useful to investors because strategies based upon these rankings yield positive abnormal returns.



In recent years, some institutions have been very active in publishing and  selling  rankings of financial analysts. Some rankings  are based on privately held surveys of  buy-side analysts (e.g., the Institutional Investor's rankings of the All-America Research Teams\footnote{\url{http://www.institutionalinvestor.com/Research/4560/First-Team.html}} and Bloomberg's America's Best Stock Analysts\footnote{\sloppy \url{http://www.bloomberg.com/news/2013-08-14/jpmorgan-top-stock-picker-with-equities-out-of-lockstep.html}}); others are based on the performance of sell-side analysts (ThomsonReuters' top StarMine analysts\footnote{\url{http://excellence.thomsonreuters.com/award/starmine}}). In any of these cases, the rankings aim at identifying the top analysts. However, aside from personal acknowledgment among peers, it is still arguable whether these are useful to investors \citep{desai2000ass} or are merely ``popularity contests" \citep{emery2009}. %In this paper, we support the argument that the top-ranked analysts, indeed, have stock picking skills.


We show that the top ranked analysts have stock picking skills. The contributions of our research is fourfold. First, we develop a trading strategy that transforms the rankings of financial analysts into inputs for the Black-Litterman model \citep{black1992}. Second, we show that annualized cumulative returns generated by some trading strategies  based upon analysts' rankings outperform a passive strategy (e.g., buy-and-hold the general stock market index). Third, we show that the strategy based upon the perfect foresight of rankings yields the highest cumulative annualized return. Fourth, we find that investors  are better off following analysts that issue the most accurate target prices, rather than those that issue the most accurate EPS forecasts.



The paper is organized as follows: section \ref{sec:ranking} provides motivation to use rankings of financial analysts; section \ref{sec:trading} outlines our proposed  trading strategies; section \ref{sec:rankings} describes the sample and presents some preliminary results; section \ref{sec:results} presents and discusses the results; and section \ref{sec:conclusion} concludes.

\section{Industry Rankings of Financial Analysts}
\label{sec:ranking}

In the financial literature there has been a long debate on whether financial analysts produce valuable  advice. Some argue that following the advice of financial analysts,  translated as recommendations of buying, holding, or selling a particular stock, does not yield  abnormal returns, i.e.,  returns that are above the required return to compensate for risk. The Efficient Market Hypothesis \citep{fama1970ecm} states that financial markets are efficient and that any public available information  regarding a stock would be immediately reflected in prices; hence, it would be  impossible to generate abnormal returns based upon past information.

Yet, several authors have since stressed that  there are information-gathering costs and information is not immediately reflected on prices  \citep{grossman1980iie}. As such, prices may not  reflect all the available information at all time because if this were the case, those who spent resources to collect and analyze   information would not have an incentive to do it, because there would not get any compensation for it.

%Many trading strategies try to forecast the price movements relying on the historical prices or estimate the intrinsic value of a company. Obviously, this type of research is associated with significant amount of up-front costs to acquire databases, software, etc. On the other hand, financial analysts have these tools and, presumably, skills to identify  stocks that worth be invested. Thus, for an investor, it is cheaper to follow the recommendations of financial analysts rather than perform a proper stock market analysis.


Some authors show that financial analysts' recommendations create value to investors \citep{womack1996,barber2001}\footnote{\cite{womack1996} finds that  post-recommendation excess returns are not mean-reverting, but are significant and in the direction forecast by the analysts. \cite{barber2001} finds that over the period of 1986-1996 a portfolio of stocks with the most (least) favorable consensus analyst recommendations yields an average abnormal return of 4.13 (-4.91)\%.}. Assuming that some analysts produce valuable advice it makes sense to rank analysts based on the accuracy of their recommendations. 

StarMine rankings are based on financial analysts' accuracy either on TP or EPS forecasts. To rank analysts based on EPS forecasts, StarMine developed a proprietary metric called a Single-stock Estimating Score (SES). This score measures ``... [a] relative accuracy; that is, analysts are compared against their peers. An analyst's SES can range from 0 to 100, with 50 representing the average analyst. To get a score higher than 50, an analyst must make estimates that are both significantly different from and more accurate than other analysts' estimates"\footnote{\url{http://excellence.thomsonreuters.com/award/starmine?award=Analyst+Awards&award_group=Overall+Analyst+Awards}}.


As for target price ranking, StarMine's methodology compares the portfolios based on analysts recommendations. Portfolios are constructed as follows. For each ``Buy'' recommendation, the portfolio is one unit long the stock and simultaneously one unit short the benchmark. ``Strong buy'' gets a larger investment of two units long the stock and two units short the benchmark. ``Hold'' invests one unit in the benchmark (i.e., an excess return of zero). ``Sell" recommendations work in the reverse way. StarMine re-balances its calculations at the end of each month to adjust for analysts revisions (adding, dropping or altering a rating), and when a stock enters or exits an industry grouping.


Recent evidence suggests that top ranked financial analyst affect market participants: prices seem to react more to the recommendations issued by the top-ranked analysts \citep{emery2009}. As such, StarMine ranking based models can be used to identify such analysts and generate superior estimates (e.g., SmartEstimates\footnote{\url{http://www.starmine.com/index.phtml?page_set=sm_products&sub_page_set=sm_professional&topic=analytical&section=accurate_estimates}}).
%Evidence shows that market response to analysts' recommendations is stronger when analysts issue them with a good forecasting tracking record \citep{park2000analyst,loh2006aef}. Thus, it seems to be the case that only a subset of analysts influences the stock prices and, as such, only that subset of analysts deserves to be followed \citep{loh2011}.



The goal of our study is to evaluate if and how rankings  add value to investors.  With this purpose, we develop several sets of active trading strategies, selecting the stocks most favored by analysts. The first strategy is based on the consensus estimate (giving equal weights to analysts' recommendations). The second set of strategies takes in consideration the analysts' target price and EPS accuracy ranks to form ``smart estimates". For the latter set of strategies, we analyse different time information sets to define the accuracy of the analysts.


We compare the performance of the strategies based upon two types of rankings (target price and EPS forecast accuracy). By doing this, we indirectly address the ongoing debate in the literature on whether analysts, when issuing the target price reports, rely on simple growth-based models or use more complex models (such as the residual income model of \cite{ohlson1995}). For example, \cite{bradshaw2004} suggests that analysts' EPS forecasts are consistent with their price targets and that analysts use growth models based on EPS forecasts to estimate stocks target prices. Differently, \cite{simon2011} argue that the most accurate analysts rely on more complex models in setting their price targets. \footnote{A further major development in the theoretical accounting literature on equity valuation models is the abnormal earnings growth (AEG) model of \cite{ohlson2005}, which relates share price to the level of expected earnings per share.}



% and it is, in a sense, an upper bound of all trading strategies.

%In addition, for each strategy, we have three timing scenarios of when we know the analysts' information: we use the \tr{} timing for the case when the information is known at time $t$ (a hypothetical case); we use the \naive{} timing for the $t-1$ case, and we use the \default{} timing \citep{aiguzhinov2010} for the $t=1 \ldots t-1$ case.

%We claim that the ranking strategies outperform the consensus ones as well as the passive strategy.


%we investigate the problem with two ranking  methods that are used further as the inputs for the trading strategy. The first is the \naive{} rankings and this is simply the last known analysts' actual rankings. The second method is taken from the Machine Learning literature \citep{aiguzhinov2010} and it is so-called the \default{} ranking. It is the average rank of an analyst since the beginning of the sample period and it encompasses the average analyst's relative performance. We formalize these methods in the appropriate section of the paper.

\section{Trading Strategies}
%- BL model
%- Information sets
\label{sec:trading}
Our trading strategy uses the framework for  active portfolio management proposed by \cite{black1992}.  The model incorporates ``views" in a CAPM framework, forming optimal portfolios in a mean-variance optimization setting. ``Views" are expectations on individual stocks' future performance.

While in the CAPM model expected returns are a function of systematic risk, in the BL model some stocks can be over- or under-priced and, therefore, their alphas are non-zero. The model blends the subjective views of investors about future performance of a stock with the market implicit returns given by CAPM.

\cite{da2011bl} apply the BL model and use the consensus expected returns as a proxy for views. They report that the resulting strategy outperforms a passive buy-and-hold strategy. Our approach is similar to theirs but we define views not only based on consensus estimates but also on smart estimates that account for previous analysts' TP and EPS accuracy.

Here below we kept the notation in \cite{black1992}.  $Q$ is the vector of  expected returns for the eligible stocks; $\Omega$ matrix is the confidence of $Q$. Altogether these two reflect the views of a particular analyst or a set of analysts.

To proxy expected returns we compare the analyst' 12-month target price (TP) with today's stock price. Confidence $\Omega$ for stock is based on variation  of forecasts across analysts which is similar to the measure of dispersion in analysts' opinions outlined in \cite{diether2002}.


We define a trading strategy as follows (figure \ref{fig:bl}):
\begin{enumerate}
\item  At the beginning of quarter $t$ for each stock $i$,   we define $Q$ and $\Omega$ (see \ref{def-q} and \ref{def-omega} below);

\item Using the market price information available at the last day of quarter $t-1$, we obtain the market implicit returns for each stock $i$,  and the variance/co-variance matrix;

\item We apply the BL model to get  optimal portfolio weights on the basis of combining views and implicit returns. We  buy or sell stocks accordingly. At the beginning of $t+1$, based on the new views, we set the new portfolio weights following  steps 1--3.
\end{enumerate}

\subsection{Defining $Q$}
\label{def-q}

For the consensus strategy, we use median of expected returns for a particular stock $i$:
\begin{equation}
\label{consq}
Q_{cons,i}= \median \left\{r_{j,i}\right\}
%\frac{1}{N} \sum_{j=1}^{N} r_{j,i}
\end{equation}
%$N$ is the number of analysts with a valid TP report and
where $r_{j,i}=TP_{j,i}/P_{i}-1$  is the last known analyst's $j$ expected return computed using the analyst price target $TP_{j,i}$ and stock price $P_{i}$\footnote{Consistent with the literature, we use stock price 3 days \emph{ex-ante} the TP announcement. This is done to avoid any information leakage around new TP announcement day \citep{bonini2010}}. 

For the strategies that weight the analysts' estimates of expected return the weight of each analyst $j$ is based on his/her rank such that the top analyst has the weight of 1 and then the weights diminish as the rank increases.


\begin{equation}
\label{eq:weight}
w_{j,i}=1-\frac{rank_{j,i}-\min_i{ \{rank \} }}{\max_i{\{rank \}}}
\end{equation}

The expected rank-weighted return is thus:
\begin{equation}
\label{rankq}
Q_{rank,i}=\frac{\sum_{j=1}^{N} (w_{j,i} \times r_{j,i})}{\sum_{j=1}^{N} w_{j,i}}
\end{equation}
$N$ is the number of analysts.

As mentioned above, we use both target price and EPS accuracy rankings.

\subsubsection{Target Price ranking} 
%%% change s to i for stock
Analysts are ranked on the basis of Proportional Mean Absolute Forecast Error (PMAFE) that measures the accuracy of a forecast  \citep{clement1999,brown2001,ertimur2007}. First,  we define the forecast daily error  $FE_{j,i}$ as the absolute value of the difference between analyst' target price $TP_{j}$ and the daily stock price $P$ for each stock $i$:

\begin{equation}
\label{dfe}
FE_{j,i}^{TP}=|{P_{i}-TP_{j,i}}|
\end{equation}
The PMAFE is given as:
\begin{equation}
\label{tp:pmafe}
PMAFE_{j,i}^{TP}=\frac{FE_{j,i}^{TP}}{\overline{FE_{i}^{TP}}}
\end{equation}
where $\overline{{FE}_{i}^{TP}}$ is the average forecasting error across analysts. The target price is fixed over the quarter unless it gets revised.

The rank  that enters equation (\ref{eq:weight}) is average analyst's $PMAFE^{TP}$ over a particular quarter:
\begin{equation}
\overline{PMAFE_{j,i}^{TP}}=\frac{1}{T} \sum_{t=1}^{T} PMAFE_{j,t,i}^{TP}
\end{equation}

\begin{equation}
\label{tp:rank}
rank_{j,i}=\rank_{j=1}^{N} \left\{ \overline{PMAFE_{j,i}^{TP}} \right\}
\end{equation}
where $T$ are the number of trading days in a quarter and $N$ is the number of brokers with a valid TP.  Figure \ref{fig:example} shows an example.


\subsubsection{EPS ranking} 
To compute the EPS rankings, we apply the same procedure as above:
\begin{equation}
FE_{j,i}^{EPS}=|{ACT_{i}-PRED_{j,i}}|
\end{equation}
\begin{equation}
PMAFE_{j,i}^{EPS}= \frac{FE_{j,i}^{EPS}}{\overline{FE_{i}^{EPS}}}
\end{equation}
\begin{equation}
\label{eps:rank}
rank_{j,i}=\rank_{j=1}^{N} \left\{ PMAFE_{j,i}^{EPS} \right\} 
\end{equation}
where $ACT_{i}$ and $PRED_{j,i}$ are the actual quarterly EPS and  analyst $j$'s EPS forecast for stock $i$.


\subsection{Defining the confidence of expected returns $\Omega$}
\label{def-omega}
The confidence of $Q$ is given by the coefficient of variation (CV) of forecasting errors. For each stock $i$ is given by:

\begin{equation}
CV_{i} = \frac{\sigma_i (FE_{i})}{\overline{FE}_{i}}
\end{equation}
where $\sigma_i$ and $\overline{FE}_i$ are the standard deviation and the mean of the forecast errors across analysts for either TP or EPS. A low value of $CV$ reflects consensual estimates of either future prices or EPS.



\subsection{Information sets to define the views}

To proceed with the trading strategy, we need to establish which information we  will be using to build the rankings. These rankings will be the inputs to compute the weighted return estimates (``smart estimates"). Different analysts' ranks are obtained  if we select different time horizons. If we use only the most  recent information, we will capture the recent performance of the analysts. This, of course, is more sensitive to unique episodes (e.g., a quarter which has been surprisingly good or bad). If, alternatively, we opt to incorporate the entire analyst performance, the ranking is less affected by such events, yet it may not reflect the current analyst ability. We use two information sets: the first uses only the  information about the analyst' performance in period $t-1$; the second, uses all the available  information for that particular analyst. We call the former the \naive{} set and the latter the \default{} set. 

In addition to these sets,  we also create a hypothetical scenario that assumes we anticipate perfectly the future analyst accuracy performance  that would only be available at the end of $t$.  This represents the perfect foresight strategy. Therefore, it serves a performance reference point to evaluate the other trading strategies. We call this the \tr{} set. 

Formalizing information sets considered are: 
\begin{itemize}
\item  the \tr{} set%-- a perfect foresight information:
\begin{equation}
\label{q:true}
\widehat{Q_{rank,i,t}}=Q_{rank,i,t}
\end{equation}
% 
\item  the \naive{} set % -- $t-$ information:
\begin{equation}
\label{q:naive}
\widehat{Q_{rank,i,t}}=Q_{rank,i,t-1}
\end{equation}
% 
\item  the \default{}  set%-- the entire history of analysts performance:
%\begin{itemize}
%\item ranking based views:
\begin{equation}
\label{q:default}
\widehat{Q_{rank,i,t}} = \frac{1}{T-1} \sum_{t=1}^{T-1} Q_{rank,i,t}
\end{equation}
%\item consensus based views:
%\begin{equation}
%\label{default.cons}
%\widehat{consQ_{t,i}} = \frac{1}{T} \sum_{T=1}^{T-1} consQ_{t,i}
%\end{equation}
%\end{itemize}
\end{itemize}
where  $Q_{rank,i,.}$ is the smart estimate for stock $i$ (eq. \ref{rankq}). For the case of consensus based expected returns ($Q_{cons,i}), the \tr{} information set is not applicable as analysts have equal weights.


\section{Data and preliminary results}
\label{sec:rankings}

\subsection{Database and sample}
We focus on the  S\&P500 stocks. We extract the target price information and the EPS forecasts from ThomsonReuters  I/B/E/S detailed history database. The  S\&P500 constituents' list and the stock daily prices are from ThomsonReuters DataStream.


Over the sample period, the total number of brokers\footnote{We use words ``analyst" and ``broker" interchangeably.} in TP dataset is \Sexpr{q.data[!is.na(b.view),.N,by=Broker][,.N]}, covering \Sexpr{q.data[!is.na(b.view),.N,by=Stock][,.N]} S\&P500 stocks. Given the fact that financial analysts commonly issue TP with the one year horizon \footnote{According to Wharton Research Data Services (WRDS), 92.33\% of all price targets reported in I/B/E/S have a 12-month horizon \citep{glushkov2009}.}, we assume that analysts keep their TP forecasts valid for one calendar year unless it is revised. After one year we assume that TP recommendation expires.

Consistent with other studies on analysts' expected returns that work with price targets  \citep{bradshaw2002,brav2003,da2011}, we truncate the sample of $TP/P-1$ at the \Sexpr{ trunk.percent *100}\textsuperscript{th} percentile (values below \Sexpr{q.data[,min(trunk.view,na.rm=T)]}) and at the \Sexpr{(1-trunk.percent)*100}\textsuperscript{th} percentile (values above \Sexpr{ q.data[,max(trunk.view,na.rm=T)]}). This is done due to occurrence of the extreme values. Most of these extreme values are driven by misalignment errors found on I/B/E/S data\footnote{We found some differences between the  DataStream and I/B/E/S the databases. In some cases the stock-splits and the dividends were not properly adjusted.}. After trimming, the number of observations ($\mathrm{Stock} \times \mathrm{Broker} \times  \mathrm{Quarter}$) is reduced  from \Sexpr{ prettyNum(q.data[,.N], big.mark=' ')} to \Sexpr{ prettyNum(q.data[!is.na(trunk.view),.N],big.mark=' ')}.

The initial file of quarterly EPS forecast consists of  \Sexpr{eps.dt[,.N,by=.(Broker)][,.N]} brokers covering \Sexpr{eps.dt[,.N,by=Stock][,.N]} stocks. To implement the EPS ranking, we require that a stock had at least three brokers per quarter. In addition, we require that a broker has to be active in covering a particular stock for at least 3 years (12 quarters). Our sample of EPS forecasts consist of  \Sexpr{complete.dt[,.N,by=Broker][,.N]} brokers covering \Sexpr{complete.dt[,.N,by=Stock][,.N]} stocks. Finally, we consider stocks that have both EPS and TP forecasts in a given quarter. The total number of stocks in our sample, thus, is \Sexpr{pt.rank.views[,.N,by=.(type,Stock)][type==sel.s,.N,by=type][,N]} stocks.

%The total number of observation is \Sexpr{prettyNum(complete.dt[,.N],big.mar=' ')}.  
 

Table (\ref{tab:ret-stat}) shows the distribution of the final sample of target price and EPS data. Panel A shows the number of quarterly target prices per stock. For the sample period (1999-2009), we report \Sexpr{prettyNum(core.dt[,.N,by=list(Stock,q.id)][,.N],big.mark=' ')} stock-quarter observations. Each stock had on average of \Sexpr{core.dt[,.N,by=list(Stock,q.id)][,mean(N)]} quarterly target price reports. Panel B  presents similar statistics of the number of EPS forecasts. In total, the EPS forecast sample has \Sexpr{prettyNum(complete.dt[,.N,by=list(Stock,q.id)][,.N],big.mark=' ')} stock-quarter observations. The average number of quarterly forecasts is \Sexpr{complete.dt[,.N,by=list(Stock,q.id)][,mean(N)]}.

We apply the ranking procedure outline in section \ref{def-q} to the two datasets. For target price rankings, we use the average daily errors within one quarter as the measure of analysts' forecasting ability (eq. \ref{tp:pmafe}). 

Table \ref{tab:example} and figure \ref{fig:example} illustrate an example illustrate how we estimate the \textit{PMAFE}. Four analysts had valid target prices for Amazon for second quarter of 1999. We plot the daily Amazon price against the brokers' target prices. Table \ref{tab:example} shows the resulting TP and EPS rankings. On the bases of the average daily errors, LEGG is the most accurate in forecasting stock price and  DLJ is the least accurate. For the EPS case (panel B), PACCREST is the most accurate in EPS forecasting and RBRTSON is the least. 


%The daily frequency allows us to capture the analysts' performance with better precision. Panel A of table (\ref{tab:example}) shows an example of rankings based on target prices. As we observe, during the second quarter of 1999, four analysts have valid target prices for Amazon (AMZN) stock. At the end of the quarter, we calculate the average daily error for each of the analysts and apply equations (\ref{tp:pmafe}) and (\ref{tp:rank}) to obtain the ranks of each of the analysts. Figure (\ref{fig:example}) demonstrates the daily AMZN stock price and the levels of the analysts' target prices. The model gives to brokers the follow ranking: LEGG(1), MONTSEC(2), KAUFBRO(3), DLJ(4). In this example, LEGG is the most accurate in forecasting the AMZN stock and DLJ is the least.
\subsection{Ranking contingency results}
We consider  three terciles (\textit{top}, \textit{medium}, \textit{bottom}). In one particular quarter ($t$), we place  analysts at one of these bins which corresponds to a tercile. We, then,  check analysts position at the immediate next quarter ($t+1$) and after one year ($t+4$).   

Beforehand, we convert the rankings into scores as follows:
\begin{equation}
\label{eq:score}
score_{j,i}=\frac{rank_{j,i}}{\max{rank_i}}
\end{equation}

To get the cross-sectional values of scores across different stocks, we take the average of $score_{j,i}$
\begin{equation}
\label{eq:mean-score}
\overline{score_{j}}= \frac{1}{k} \sum_{s=1}^{k} score_{j,i}
\end{equation}
where $k$ is number of stocks followed by a particular analyst $j$. 

Table (\ref{tab:rank-stat}) shows a contingency analysis of the ranks. 
%Chi square statistics include/ expected frequiency test
%Journ. of Fin economics 
Panel A shows the dynamics of each tercile for rankings based on target price  accuracy. We observe that analysts exhibit strong ranking consistency as, on average, they stay at the same tercile after one quarter. Of the top (bottom) most accurate (inaccurate) analysts in the previous quarter \Sexpr{pt.cont.tab[1,1,1,1]*100}\% (\Sexpr{pt.cont.tab[3,3,1,1]*100}\%) remain in that same tercile after one quarter. After one year the corresponding figures are lower respectively \Sexpr{pt.cont.tab[1,1,1,2]*100}\% and \Sexpr{pt.cont.tab[3,3,1,2]*100}\% for the top and bottom terciles. 

In the case of EPS ranking  (panel B) \Sexpr{eps.cont.tab[1,1,1,1]*100}\% and  \Sexpr{eps.cont.tab[3,3,1,1]*100}\% ( \Sexpr{eps.cont.tab[1,1,1,2]*100}\% and  \Sexpr{eps.cont.tab[3,3,1,2]*100}\%) of the analysts  remained in the top and bottom terciles after one quarter (year)  respectively.

These results are consistent with the recent findings of \cite{hilary2013} on analyst forecast consistency. 

%the next quarter  $top_{t+1}$ group is as follows: \Sexpr{round(pt.cont.tab[[1]][1,1],3)*100}\%  of analysts stay at the same ranking category from the $top_{t-1}$; \Sexpr{round(pt.cont.tab[[1]][2,1],3)*100}\% move from the $middle_{t-1}$; \Sexpr{round(pt.cont.tab[[1]][3,1],3)*100}\% from the $bottom_{t-1}$. It is clear to observe that the $top_{t}$ category, on the average, mostly consists of brokers from the past quarter \emph{middle} rank. %Observe that for the $noRank_{t}$ category, most of the contribution comes from the same category of the past quarter (\Sexpr{round(cont.tab[[1]][4,4],3)*100}\%). This suggests that analysts are not frequent in issuing target price reports.

%This also represents ... variation to justify the effor of  trying to update the ranking every quarter in order to 
%An interesting observation is for the \emph{noRank} category: \Sexpr{ round(cont.tab[[2]][4,1],3)*100}\% of the analysts who did not have rankings in the current quarter once issued a target price report move to the \emph{top} in the following quarter. 

%Panel B depicts the similar analysis for the EPS forecast rankings. For this case, we observe that the composition of the $top_{t}$ is quite similar to the  one we see in target price case: the most contributive group for $top_{t}$ is the \emph{middle} ranks from $t-1$. %However, one interesting observation is that $noRank_{t-1}$ shows significant contribution for each of the ranking groups in $t$: for the \emph{top} ranking it contributes \Sexpr{round(eps.cont.tab[[1]][4,1],3)*100}\%, for the \emph{middle} --- \Sexpr{round(eps.cont.tab[[1]][4,2],3)*100}\%, and for the \emph{bottom} --- \Sexpr{round(eps.cont.tab[[1]][4,3],3)*100}\%. This suggests that analysts, probably, issue the EPS forecasts after the availability of firm's management EPS forecast as that could entail new information about a firm \citep{hassel1986}.



\subsection{Views: descriptive statistics}

Table \ref{tab:view-stat} present the descriptive statistics of the analysts' expected returns conditional on the different information sets. 
%Panel A shows the expected returns based on the analysts consensus and Panel B and C are based on the smart estimates (TP and EPS).


The expected returns  are computed comparing TP estimates with actual prices. To form the smart strategies we compute rank-weighted estimates where weights are given either by the TP or the EPS ranks. 

\cite{bradshaw2002} reports analyst average expected returns for the period of 2000--2009 and 206 brokers of 24\%. \cite{da2011} report an average expected return of 40\% for the period of 1996--2004. \cite{zhou2013} finds an average expected return of 96\% for the sample period of 2000--2009. These figures suggest that analysts are overly optimistic.
%these values from the historical perspective, i.e., how the values of expected stock returns go inline with historical stock returns. \cite{bodie2009} show that arithimatic average rate of return for the U.S. large stocks (S\&P 500) for the period of 1926--2005 is 10.17\% and the average rate of excess return is 8.39\% with the risk premium estimated 6--8\%. While it is not the best idea to extrapolate the historical values, still, we can say that the expected stocks return should be around 14--16\%. Clearly, the values presented in the literature shows that analysts are very optimistic in issuing target price reports.

Panel A show the statistics for the consensus expectations as defined in eq. (\ref{consq}). The average consensus among the analysts on stock expected returns in the  \naive{} and \default{} information sets are, respectively, \Sexpr{test.a['Total',,'CONS','mean',sel.s][[2]]*100 }\%, and \Sexpr{test.a['Total',,'CONS','mean',sel.s][[3]]*100}\% respectively. Panel B of the table shows the TP accuracy weighted average expected returns (\Sexpr{test.a['Total',,'PT','mean',sel.s][[1]]*100 }\%, \Sexpr{test.a['Total',,'PT','mean',sel.s][[2]]*100 }\%, and \Sexpr{test.a['Total',,'PT','mean',sel.s][[3]]*100}\%). Panel C shows the EPS based weighted expected returns averages (\Sexpr{test.a['Total',,'EPS','mean',sel.s][[1]]*100 }\%, \Sexpr{test.a['Total',,'EPS','mean',sel.s][[2]]*100 }\%, and \Sexpr{test.a['Total',,'EPS','mean',sel.s][[3]]*100}\%). 

Overall compared to the consensus the ranked weighted expected returns (smart estimates) are less optimistic. The \default{} information set shows higher values of expected returns.

Table \ref{tab:stocks} shows the number of active stocks for each of the trading strategies (\textit{CONS}, \textit{TP}, and \textit{EPS}) conditional on considered information sets.
%obtained from the rankings based on the target price accuracy. We observe a reduction in average per stock expected return with the mean of \Sexpr{ round(rank.views.full.period['true','mean'],3)*100}\%. The case of rankings based on EPS forecasts (panel C) shows even more moderate average stock expected return of \Sexpr{ round(pt.eps.rank.views.full.period['true','mean'],3)*100}\%. Overall, compared to the consensus, both ranking-based methods exhibit less optimistic expected returns and are pretty close to the historical averages.


%put in to the different section

\section{Empirical Results}
\label{sec:results}

We report the results from different trading strategies in table (\ref{tab:strategy}). We split the table into four panels. Panel A shows  the performance for  the passive (market) strategy \textit{Market}. Panels B to D compare the consensus , the TP rank weighted and the EPS rank weighted trading strategies for each of the information availability sets. 


\subsection{Passive strategy}

The passive strategy generates an annualized cumulative return of \Sexpr{bl.results['Market',1,1,sel.s]}\% with a Sharpe Ratio  of \Sexpr{bl.results['Market',1,'ann.sr',sel.s]} over the period 1999-2001. The average number of stocks held per quarter was \Sexpr{bl.results['Market',1,'meanViews',sel.s]} and the turnover ratio was \Sexpr{bl.results['Market',1,'Ave.TO',sel.s]}, which reflects solely the inclusion and deletions  of the S\&P 500 constituent list.

\subsection{Perfect foresight strategy}
\label{sec:perfect}
Panel B presents the results for the case of the \tr{} information set. The annualized cumulative returns for each of the active strategies (\textit{TP}, and \textit{EPS}) are, respectively, \Sexpr{bl.results['TP',1,1,sel.s]}\%, \Sexpr{bl.results['EPS',1,1,sel.s]}\%. All the strategies outperform the passive benchmark (\Sexpr{bl.results['Market',1,1,sel.s]}\%). The results show, as expected, that  we would better off if we knew in advance who the top analysts in terms of TP accuracy would be. In any case, the results suggest that the advice of analysts, as a group, is valuable. 
%Yet, the top analyst  

%The result confirms that these strategies set an upper bound for the cumulative return yield. It follows, that we setup a boundary for the results of the feasible strategies: the upper bound is the perfect foresight strategy and the lower bound is the market benchmark.

The \textit{TP} ranking strategy dominates also when we look at the risk-adjusted returns. The Sharpe Ratio is \Sexpr{ bl.results['TP',1,'ann.sr',sel.s]} against \Sexpr{ bl.results['EPS',1,'ann.sr',sel.s]} and \Sexpr{ bl.results['Market',1,'ann.sr',sel.s]}, respectively for the \textit{EPS}and the \textit{Market} strategies. In addition, the \textit{TP} strategy dominates  the others if we consider the smaller trading periods (5 years). Table \ref{tab:substrategy} shows the Sharpe Ratio for six 5-year holding periods. The \textit{TP} strategy wins over the others in every period as expected.

While this is an hypothetical setting, given that it is not possible to know in advance which analyst will rank first, it suggests that if we can predict the rankings with some accuracy this will be a useful investment trading tool. One of the possibilities is using methods developed in the Machine Learning literature (e.g., \cite{aiguzhinov2010,brazdil2003}), where this type of problem (referred as a label ranking problem) has been broadly studied. For example, \cite{aiguzhinov2010} propose a label ranking algorithm using Bayesian approach to predict the rankings.



\subsection{Feasible strategies}
Panel C of table (\ref{tab:strategy}) shows the performance of the different smart strategies in the \naive{} information set. As it was the  case of the \tr{} information set, all the active strategies outperform the \textit{Market} (\Sexpr{bl.results['Market',2,1,sel.s]}\%)  and show positive cumulative annualized returns of \Sexpr{bl.results['TP',2,1,sel.s]}\%,  \Sexpr{bl.results['CONS',2,1,sel.s]}\%, \Sexpr{bl.results['EPS',2,1,sel.s]}\% respectively for the \textit{TP}, the \textit{CONS}, and the \textit{EPS} strategies. Similarly, the \textit{TP} strategy dominates when we consider the risk-adjusted returns. The Sharpe Ratio for this strategy is \Sexpr{ bl.results['TP',2,'ann.sr',sel.s]} which is higher than that Sharpe Ratios of the \textit{CONS} and  the \textit{EPS} strategies  (\Sexpr{ bl.results['CONS',2,'ann.sr',sel.s]} and \Sexpr{bl.results['EPS',2,'ann.sr',sel.s]} respectively). The results in panel B of table \ref{tab:substrategy} show as well that this strategy outperform the others for all of 5 trading sub-periods. 

Panel D of table \ref{tab:strategy} confirm the outperformance of the \textit{TP} smart strategy: this is the the only active strategy that yields positive annualized cumulative return (\Sexpr{bl.results['TP',3,1,sel.s]}\%) whereas both  the \textit{CONS} and the \textit{EPS} show negative returns (\Sexpr{bl.results['CONS',3,1,sel.s]}\% and \Sexpr{bl.results['EPS',3,1,sel.s]}\% respectively). The panel C of table \ref{tab:substrategy} shows that the Sharpe Ratio of the \textit{TP} strategy is lower then that of the \textit{EPS} strategy in only first two sub-periods (2000Q1/2004Q4 and 2001Q1/2005Q4).


Figure \ref{fig:bl-results} shows the graphical representation of the cumulative portfolio wealth for  the passive and smart strategies in all the information sets. The $y$-axis is the monetary value of wealth and $x$-axis is the time starting at \Sexpr{ months(as.Date(final.bl[,head(Quarters,1)]))} of \Sexpr{start.year } and ending at \Sexpr{ months(as.Date(final.bl[,tail(Quarters,1)])+91)} of \Sexpr{end.year}. Figures show that strategies under the \tr{} panel outperform the \emph{Market} and that final value  of the portfolio of the TP strategy considerably outruns the other alternative strategies.


In sum the results of  feasible information sets outlined above suggest that  it is worth to follow the top analysts and are supportive of \cite{desai2000ass} in that rankings are useful for investors.



%The results of trading strategies suggest that the dominant trading strategy is \textit{TP} strategy which is based on the accuracy of analsyts' TP reports. Thus, an investor is better off when following the analysts who issue more accurate target price; hence, rankings are usefull for the investors.

%do identify the best analysts and this findings supports the argument of \cite{desai2000ass}. In addition, the results show that keeping all available information about analysts' performance does not create any value. As we see, the \default{} strategy is the worse in term of the annualized cumulative returns. 

Finally, the results suggest that, from an investor's point of view, following analysts who are accurate in setting price targets is more valuable than following those that good at forecasting EPS.  This result contradicts the findings of \cite{bradshaw2004} and supports the argument of \cite{simon2011} that the stock recommendations of the most accurate analysts are not based upon the simple valuation models.

\section{Conclusions}
\label{sec:conclusion}

Some institutions, such as StarMine, rank financial analysts based on EPS and target price accuracy. These rankings are published and are relevant: stocks favored by top-ranked analysts will probably receive more attention from investors. Therefore, there is a growing interest in understanding the relative performance of strategies based upon analysts forecasts.

By applying the Black-Litterman model, we developed simulations of trading strategies using  different information sets. The perfect foresight scenario (using the information know at time $t$) sets the upper bound of the trading strategies in terms of the maximum yield any such strategies could achieve. If only the information known at time $t-1$ is used, investors would be better off following the strategy that weights more heavily the estimates given by the most accurate TP forecast analysts.

%We report that under the \tr{} information (the information known at time $t$) about stock's expected return we get the upper bound of the trading strategies, . The \naive{} information (the information known at time $t-1$) create more value from the following the top-ranked analysts who set accurate stock price targets. %The \default{} information (the information known from the beginning up to $t-1$), because of its outdated nature, fails to show any positive outcomes and the passive strategy is the only choice for this information set.

For the future work we will developed new methods to forecast analysts rankings so us to get closer to the upper bound.


\bibliographystyle{chicago}
%\bibliographystyle{newapa}
\bibliography{rank}


%\section{Tables and Figures}


\newpage
%Descriptive  table
\begin{table}[hp]
  \caption{Sample Statistics}
  \label{tab:ret-stat}
\ This table shows the average number of target prices  (panel A) and EPS forecasts (panel B) per stock per quarter.

\begin{tabularx}{\linewidth}{r*{6}{Y}}
    \toprule
Year & Min& Mean & Median &Max& Std.dev\\
\midrule
%Panel A: TP&&&&&\\
\multicolumn{6}{c}{\textbf{Panel A: TP}} \\
\midrule
%Year & Min& Mean & Median &Max& Std.dev\\
<<desc-pt,echo=F,results='asis'>>=

#data.to.display <- c('min','mean', 'median','max','std.dev')
#results.final <- rbind(brok.full.stat.pt[,data.to.display],'Total period'=setkey(pt.full.period,Statistics)[data.to.display][,value])

options(xtable.comment = FALSE)
#cat(rep('&',ncol(results.final)),'\\\\')
print(xtable(brok.full.stat.pt,display=c('s','f','d','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,include.rownames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(11),command=c('\\midrule \n')))
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{6}{Y}}
\midrule
\multicolumn{6}{c}{\textbf{Panel B: EPS}} \\
\midrule
<<desc-eps,echo=F,results='asis'>>=
print(xtable(brok.full.stat.eps,display=c('s','d','d','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,include.rownames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(11),command=c('\\midrule \n')))
@
\bottomrule
\end{tabularx}
\end{table}


\begin{table}[hp]
  \caption{Example of ranking}
  \label{tab:example}
\ This table shows target prices (panel A) and EPS forecasts (panel B) rankings for Amazon (AMZN) for the second quarter of 1999. We apply (\ref{tp:rank}) to obtain the ranks of the brokers. \emph{TP} are target prices; $\overline{PMAFE}^{TP}$ is the daily average proportional mean adjusted TP error. For the EPS case, $PRED$ are the EPS forecasts issued by the analysts; $PMAFE^{EPS}$ is the proportional mean-adjusted forecast error of quarterly EPS forecasts. 
\begin{tabularx}{\linewidth}{r*{4}{Y}}
    \toprule
    \multicolumn{4}{c}{\textbf{Panel A: TP}} \\
<<example-table,echo=FALSE,warning=FALSE,message=FALSE,results='asis'>>=
print(xtable(setnames(q.data[Stock=='AMZN'&q.id=='1999 Q2'][,list('Broker/Analyst'=Broker,'\\emph{TP}'=PT,'$\\overline{PMAFE}^{TP}$'=round(score,3))][,rank:=c(4,3,1,2)][order(rank)],4,'$rank^{TP}$'),display=c('s','d','f','f','d')),include.rownames=F,only.contents = T,hline.after=NULL,add.to.row=list(pos=list(0,4),command=c('\\midrule \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{4}{Y}}
    \multicolumn{4}{c}{\textbf{Panel B: EPS}} \\
<<example-table-eps,echo=FALSE,warning=FALSE,message=FALSE,results='asis'>>=
print(xtable(setnames(complete.dt[Stock=='AMZN'&q.id=='1999 Q2'][,list('Broker/Analyst'=Broker,'$PRED$'=Est,'$PMAFE^{EPS}$'=eps.pmafe,rank)][order(rank)],4,'$rank^{EPS}$'),display=c('s','d','f','f','d'),digits=3),include.rownames=F,only.contents=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('\\midrule \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}


<<example-fig,echo=F,include=FALSE,results='hide',fig.width=10.7,fig.height=8.3>>=
require(gridExtra)
example.dt$Broker <- factor(example.dt$Broker,levels=unique(example.dt$Broker))
test <- rbind(example.dt[,.(s.Date,PT,Series=Broker)][,Broker:='Broker'],example.dt[,.(s.Date,PT=priceAdj)][,Broker:='AMZN'][,Series:='AMZN'])
test$Series <- factor(test$Series,levels=c('AMZN',as.character(unique(example.dt$Broker))))

#ggplot(setnames(rbind(example.dt[,.(s.Date,PT,Broker)],setnames(example.dt[,.(s.Date,priceAdj)][,Broker:='AMZN'],2,'PT')),'Broker','Stock Price'),aes(x=s.Date,y=PT,group=`Stock Price`,color=`Stock Price`,shape=`Stock Price`))+geom_line(size=1)+geom_point()+theme_bw()+ylab('Dollars')+xlab('1999Q2')+ggtitle('Daily stock price (AMZN) compared to broker\'s target prices')+scale_color_grey()

#ggplot(example.dt,aes(x=s.Date,y=PT,group=Broker,color=Broker,shape=Broker))+geom_line(size=1)+geom_line(aes(y=priceAdj),color='black')+geom_point()+theme_bw()+ylab('Dollars')+xlab('1999Q2')+ggtitle('Daily stock price (AMZN) compared to broker\'s target prices')+scale_color_grey()

ggplot(test,aes(x=s.Date,y=PT,group=Series,color=Series,shape=Series))+theme_bw()+ylab('Dollars')+ggtitle('Daily stock price (AMZN) compared to broker\'s target prices \n over the period of the second calendar quarter of 1999')+geom_line()+geom_point(size=2)+scale_color_grey()+theme(axis.title.x=element_blank(),text=element_text(size=20,family='Times'),legend.title=element_blank())

#+geom_line(aes(y=priceAdj),color='black')+theme(plot.title = element_text(colour = "Black"),legend.position='top')
#grid.draw(grobTree(arrangeGrob(p,ncol=1),rectGrob(gp=gpar(lwd=2, fill=NA))))
@




 % Descritive rankings
 \begin{table}[hp]
  \caption{Analysts' accuracy consistency}
  \label{tab:rank-stat}
  
\ This contingency table shows changes in analysts'  \textit{top}, \textit{middle}, \textit{bottom} ranking bins. Panel A (Panel B) depicts the dynamics of the analysts' ranks  based on the accuracy in target prices (EPS forecasts).
\begin{tabularx}{\linewidth}{r*{6}{Y}}
    \toprule
\multirow{10}{*}{$t$}&\textbf{Panel A: TP}&\multicolumn{4}{c}{$t+1$} \\
&&$top$&$middle$&$bottom$&Sum\\

<<desc-rank-pt-t1,echo=F,results='asis'>>=
tab.r <- round(cbind(pt.cont.tab[,,sel.s,'t'],Total=apply(pt.cont.tab[,,1,1],1,sum)),3)*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,sanitize.text.function = function(x) x)

tab.r <- round(cbind(pt.cont.tab[,,sel.s,'t+4'],Total=apply(pt.cont.tab[,,1,2],1,sum)),3)*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{4}{c}{$t+4$}\\\\ \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}
\begin{tabularx}{\linewidth}{r*{6}{Y}}
\midrule
\multirow{11}{*}{$t$}&\textbf{Panel B: EPS}&\multicolumn{4}{c}{$t+1$} \\
&&$top$&$middle$&$bottom$&Sum\\
<<desc-rank-eps-t1,echo=F,results='asis'>>=
tab.r <- round(cbind(eps.cont.tab[,,sel.s,'t'],Total=apply(eps.cont.tab[,,1,1],1,sum)),3)*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,sanitize.text.function = function(x) x)
tab.r <- round(cbind(eps.cont.tab[,,sel.s,'t+4'],Total=apply(eps.cont.tab[,,1,2],1,sum)),3)*100
rownames(tab.r) <- c('&$top$','&$middle$','&$bottom$')
#colnames(tab.r) <- c('$top$','$middle$','$bottom$','Sum')
print(xtable(tab.r,hline = F,digits=1),only.contents=T,include.colnames=F,include.rownames=T,hline.after=NULL,add.to.row=list(pos=list(0),command=c('&&\\multicolumn{4}{c}{$t+4$}\\\\ \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}

\begin{table}[hp]
  \caption{Descriptive statistics of views}
  \label{tab:view-stat}
\ This table shows the descriptive statistics of views (expected returns) based on the consensus (median) among the analysts (panel A); target price rankings (panel B); and EPS forecasts rankings (panel C).

\begin{tabularx}{\linewidth}{r*{4}{Y}}
\toprule
& Mean (in \%)&Median (in \%)&Std.dev\\
%&all&same&all&same&all&same\\
\midrule
<<desc-q-cons,echo=F,results='asis'>>=
test.a[,,,1:2,sel.s] <- test.a[,,,1:2,sel.s]*100
dimnames(test.a)[[2]] <- c('\\tr{}','\\naive{}','\\default{}')
print(xtable(acast(melt(test.a[12,1:3,'CONS',1:3,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,NA.string='-',hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel A: Consensus}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{4}{Y}}
  \midrule
<<desc-q-naive,echo=F,results='asis'>>=
#data.to.display <- c('nbr.val','mean', 'median','std.dev')

#cat(rep('&',ncol(results.final)),'\\\\')
print(xtable(acast(melt(test.a[12,,'PT',1:3,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel B: TP}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
  \end{tabularx}
  
\begin{tabularx}{\linewidth}{r*{4}{Y}}
<<desc-q-eps,echo=F,results='asis'>>=
print(xtable(acast(melt(test.a[12,,'EPS',1:3,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0),command=c('\\multicolumn{4}{c}{\\textbf{Panel C: EPS}} \\\\ \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
  \end{table}
  

\begin{table}[hp]
  \caption{Number of active stocks}
  \label{tab:stocks}
\ This table shows number of active stocks in each of the trading strategies conditional on different information sets: \tr{} (panel A), \naive{} (panel B) and \default{} (panel C). 

%\resizebox{\textwidth}{!}{%
%\begin{tabular}{rrrrrrr}
\begin{tabularx}{\linewidth}{r*{4}{Y}}
\toprule
Year&\textit{CONS}& \textit{TP} &\textit{EPS}\\
%&all&same&all&same&all&same\\
<<stocks-true,echo=F,results='asis'>>=
print(xtable(acast(melt(test.a[,1,c(1,3,2),4,sel.s]),Var1~Var2,value.var='value'),display=c('s','d','d','d'),digits=3),only.contents=T,include.colnames=FALSE,NA.string='-',hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0,11),command=c('\\multicolumn{4}{l}{\\textbf{Panel A: \\tr{}}} \\\\ \n','\\midrule \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{4}{Y}}
<<stocks-naive,echo=F,results='asis'>>=
print(xtable(acast(melt(test.a[,2,c(1,3,2),4,sel.s]),Var1~Var2,value.var='value'),display=c('s','d','d','d'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0,11),command=c('\\multicolumn{4}{l}{\\textbf{Panel B: \\naive{}}} \\\\ \n','\\midrule \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{4}{Y}}
<<stocks-def,echo=F,results='asis'>>=
print(xtable(acast(melt(test.a[,3,c(1,3,2),4,sel.s]),Var1~Var2,value.var='value'),display=c('s','d','d','d'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,0,11),command=c('\\multicolumn{4}{l}{\\textbf{Panel C: \\default{}}} \\\\ \n','\\midrule \n','\\midrule \n')),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}

<<bl-results-fig,echo=FALSE, include=FALSE,results='hide',fig.width=10.7,fig.height=8.3>>=
library(scales)
#final.bl$Method <- factor(final.bl$Method,levels=sort(unique(final.bl$Method)))

colourCount = length(unique(final.bl$Views))
getPalette = colorRampPalette(RColorBrewer::brewer.pal(colourCount, "Set1"))

#p.cum.ret <-
ggplot(final.bl[type==sel.s],aes(x=as.Date(Quarters),y=cum.ret,group=Views,color=Views,shape=Views))+geom_line(size=0.5)+facet_grid(~Method,scale='free_x')+ylab('Portfolio wealth (initial=$100)')+xlab('Quarters')+ggtitle('Portfolio performance with $100 initial investment')+theme_bw()+theme(plot.title = element_text(colour = "Black"),legend.position='top',legend.title=element_blank(),strip.text=element_text(size=20),text=element_text(size=20,family='Times'))+scale_color_grey()+geom_point()+geom_hline(yintercept=100)
#
@




\begin{table}[hp]
  \caption{Trading strategies performance: entire period}
  \label{tab:strategy}
  \ This table shows the performance statistics of the different trading strategies. Panel A presents the results for the passive strategy. Panels B, C, and D show the results for the perfect foresight scenario (\tr{}), and, respectively, the scenarios for which we use the most recent  (\naive{}) and  all ranking history of analysts (\default{}) to weight the TP/EPS estimates. Within each panel, we show the strategy results of three views regarding expected return: \textit{CONS} uses the median of the analysts estimates; \textit{TP} is based upon TP accuracy ranking; and \textit{EPS} is based upon  EPS accuracy ranking. The trading period goes from \Sexpr{gsub('[[:space:]]','',final.bl[,head(Quarters,1)])} until \Sexpr{gsub('[[:space:]]','',final.bl[,tail(Quarters,1)])}.

\begin{tabularx}{\linewidth}{r*{6}{Y}}
  \toprule
  %\multicolumn{5}{l}{\textbf{Panel A: Market}} \\
<<bl-market,echo=F,results='asis'>>=

dimnames(bl.results)[[1]] <- c('\\textit{CONS}','\\textit{TP}','\\textit{EPS}','\\textit{Market}')
results.final <- bl.results[4,1,,sel.s]
cat(paste(c('Strategy','Annualized return (in \\%)','Annualized Std. dev (in \\%)','Sharpe ratio' ,'Average num. stock','Average turnover rate'), collapse = "&"),'\\\\')
#cat('\\multicolumn{5}{l}{\\textbf{Panel A: Market}} \n')
print(xtable(t(data.table('\\textit{Market}'=results.final)),display=c('s','f','f','f','d','f'),digits=3,align=c('r',rep('c',length(results.final)))),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0),command=c('\\multicolumn{6}{l}{\\textbf{Panel A}} \\\\ \n')),sanitize.text.function = function(x) x)
cat('\\midrule \n')
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{6}{Y}}
\multicolumn{6}{l}{\textbf{Panel B: \tr{} }} \\

  <<bl-nr,echo=F,results='asis'>>=
print(xtable(acast(melt(bl.results[1:3,1,,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f','d','f'),digits=3),only.contents=T,NA.string='-',include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(nrow(bl.results[1:3,1,,sel.s])),command=c('\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{6}{Y}}
  \multicolumn{6}{l}{\textbf{Panel C: \naive{}}} \\
<<bl-pt,echo=F,results='asis'>>=
print(xtable(acast(melt(bl.results[1:3,2,,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),,add.to.row=list(pos=list(nrow(bl.results[1:3,2,,sel.s])),command=c('\\midrule \n')),sanitize.text.function = function(x) x)
@
\end{tabularx}

\begin{tabularx}{\linewidth}{r*{6}{Y}}
  \multicolumn{6}{l}{\textbf{Panel D: \default{}}} \\
<<bl-eps,echo=F,results='asis'>>=
print(xtable(acast(melt(bl.results[1:3,3,,sel.s]),Var1~Var2,value.var='value'),display=c('s','f','f','f','d','f'),digits=3),only.contents=T,include.colnames=FALSE,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),sanitize.text.function = function(x) x)
@
\bottomrule
\end{tabularx}
\end{table}


\begin{table}[hp]
  \caption{Trading strategies performance: sub-periods}
  \label{tab:substrategy}
  \ This table presents the annualized return (in \%) and the Sharpe ratio of each of the trading strategies: the passive (\textit{Market}) and the active (consensus and smart estimates) calculated for different holding periods. Panel A represents the perfect foresight information set; panels B and C show, respectively, the results of the strategies using the most recent and all history analysts' performance. 

\resizebox{\textwidth}{!}{%
%\begin{tabularx}{\linewidth}{r*{9}{Y}}
\begin{tabular}{rrrrrrrrr}
\toprule
Period&\multicolumn{2}{c}{\textit{Market}}&\multicolumn{2}{c}{\textit{CONS}}&\multicolumn{2}{c}{\textit{TP}}&\multicolumn{2}{c}{\textit{EPS}} \\

& Ann.ret&SR& Ann.ret&SR& Ann.ret&SR& Ann.ret&SR\\

<<sr-true,echo=F,results='asis'>>=
periods.array[,,,,1,sel.s] <- periods.array[,,,,1,sel.s]*100
#results.final <- bl.results['Market',1,]
#cat(paste(c('Period','\\textit{Market}','\\textit{CONS}','\\textit{TP}','\\textit{EPS}'), collapse = "&"),'\\\\')
#cat('\\multicolumn{5}{l}{\\textbf{Panel A: Market}} \n')
#print(xtable(periods.array[,c(4,1,2,3),1,'yes','sr'],display=c('s','f','f','f','f'),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0),command=c('\\multicolumn{5}{l}{\\textbf{Panel A: \\tr{}}} \\\\\n')))

print(xtable(acast(melt(periods.array[,c(4,1,2,3),1,'yes',c(1,4),sel.s]),Var1~Var2+Var3,value.var='value'),display=c('s','f','f','f','f','f','f','f','f'),digits=3),only.contents=T,NA.string='-',include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,6),command=c('\\multicolumn{9}{l}{\\textbf{Panel A: \\tr{}}} \\\\\n', '\\midrule \n')))


@
\midrule
\end{tabular}}

\resizebox{\textwidth}{!}{%
\begin{tabular}{rrrrrrrrr}
%\begin{tabularx}{\linewidth}{r*{9}{Y}}
<<sr-naive,echo=F,results='asis'>>=
#print(xtable(periods.array[,c(4,1,2,3),2,'yes','sr'],display=c('s','f','f','f','f'),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0),command=c('\\multicolumn{5}{l}{\\textbf{Panel B: \\naive{}}} \\\\\n')))

print(xtable(acast(melt(periods.array[,c(4,1,2,3),2,'yes',c(1,4),sel.s]),Var1~Var2+Var3,value.var='value'),display=c('s','f','f','f','f','f','f','f','f'),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,6),command=c('\\multicolumn{9}{l}{\\textbf{Panel B: \\naive{}}} \\\\\n', '\\midrule \n')))

@
\midrule
\end{tabular}}
\resizebox{\textwidth}{!}{%
\begin{tabular}{rrrrrrrrr}
%\begin{tabularx}{\linewidth}{r*{9}{Y}}
<<sr-default,echo=F,results='asis'>>=
#print(xtable(periods.array[,c(4,1,2,3),3,'yes','sr'],display=c('s','f','f','f','f'),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0),command=c('\\multicolumn{5}{l}{\\textbf{Panel C: \\default{}}} \\\\\n')))

print(xtable(acast(melt(periods.array[,c(4,1,2,3),3,'yes',c(1,4),sel.s]),Var1~Var2+Var3,value.var='value'),display=c('s','f','f','f','f','f','f','f','f'),digits=3),only.contents=T,include.colnames=F,hline.after=NULL, format.args=list(big.mark = " ", decimal.mark = "."),add.to.row=list(pos=list(0,6),command=c('\\multicolumn{5}{l}{\\textbf{Panel C: \\default{}}} \\\\\n','\\midrule \n')))
@
\bottomrule
\end{tabular}}
\end{table}



\begin{figure}[h]
\begin{center}
\includegraphics[width=\linewidth]{figure/Black-litterman}
\end{center}
\caption{Trading strategy timeline}
\label{fig:bl}
\ Black-Litterman model inputs are at the beginning of $t$ we apply the BL model and form the active portfolio. At the end of $t$, we evaluate performance.
\end{figure}


\begin{figure}[h]
\begin{center}
\includegraphics[width=\linewidth]{figure/example-fig-1}
\end{center}
\caption{Amazon daily stock price and brokers target prices}
\label{fig:example}
\ Target price and actual prices for Amazon  the second quarter of 1999.
\end{figure}

\begin{figure}[h]
\begin{center}
\includegraphics[width=\linewidth]{figure/bl-results-fig-1}
\end{center}
\caption{Performance of the BL model}
\label{fig:bl-results}
\ Quarterly performance of the cumulative portfolio wealth for all strategies. Panel \tr{} shows the case of the known future information; \naive{} is the case of ranking information know at $t-1$, and the \default{} is the case of using all ranking information for up to $t-1$. \textit{TP} is the strategy with rankings based on the accuracy in target prices, \textit{CONS} is the strategy based on the consensus among the analysts regarding a stock's expected return. \textit{EPS} is the strategy with rankings based on the accuracy of EPS forecasts. The trading period ranges from \Sexpr{gsub('[[:space:]]','',final.bl[,head(Quarters,1)])} until \Sexpr{gsub('[[:space:]]','',final.bl[,tail(Quarters,1)])}
\end{figure}

\end{document}
